# ChatStream とは

ChatStream はスケーラブルな LLM チャットサーバー構築のためのツールキットです

### 1. ストリーミングチャットを簡単構築

HuggingFace ベースの事前学習済の大規模言語モデルの **ストリーミングチャット** を簡単に構築

**ストリーミングチャットとは**

事前学習済言語モデルで文章生成するとき、入力されたプロンプト（とこれまでの会話履歴）をもとに
次の **文章をすべて生成してから出力** する方式と、次の **文章を１トークンずつ逐次出力する** 方式があります。

前者の方式を「一括生成」、  
後者の方式をとくに「ストリーミング生成」と呼びます。

|                                | メリット                          | デメリット                                                       |
|:-------------------------------|:------------------------------|:------------------------------------------------------------|
| 一括生成                        | ・設計がシンプル                      | ・文章生成終了まで待たされる。<br>特にサーバーが込み合っているときは、<br>いつまでも結果がでずストレス |
| **ストリーミング生成** <br>(逐次文章生成) | ・逐次生成されるので、<br>文章生成完了まで待たされない | ・設計が複雑                                                      |


本パッケージでは、トークン生成を 1トークンごと に行われ、それをクライアントに対してストリーミングレスポンス（逐次送信）します。

これによりすべての文章が生成されるまで待たされるのにくらべ、ベターなユーザーエクスペリエンスの実現に寄与します

### 2. 会話履歴を保持し、会話コンテクストをキープしたマルチラウンドの会話ができる

ユーザーと 事前学習済言語モデル との会話履歴は保持されます

デフォルトでは、HTTPセッションを利用し、ブラウザが開いている間会話がキープされますが、
要件に応じてログイン機能との連動や会話コンテクストの永続化などを実装することができます。
        
### 3. 複数同時アクセス時の安定したチャットストリーム生成

複数クライアントからの同時アクセスを前提に設計されており、コンストラクタで指定された以下パラメータに従い制御することができます。

```        
num_of_concurrent_executions: int ... 事前学習済言語モデルへの文章生成タスクの同時実行数
max_queue_size: int ... 文章生成の待ち行列（キュー）のサイズ。文章生成タスクの同時実行数がリミットを下回ったらリクエストタスクはキューから取り出され文章生成タスクが開始される
```

![img](https://riversun.github.io/chatstream/chatstream_queue.png)

